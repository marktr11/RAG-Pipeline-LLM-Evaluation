# RAG Pipeline and Evaluation Methodology 
This repository implements a simple RAG pipeline that reads from PDF files and answers question. Additionally, it proposes an evaluation architecture for the pipeline.


## Project Structure

-   `PART1_RAG_IMPLEMENTATION/`: Contains the Python code for the RAG pipeline.
    -   `pipeline.py`: The main script implementing the RAG pipeline.
    -   `.env.example`: Example environment file for API keys.
    -   `output_example.txt` : Expected output
    -   `config.py` : Stores configuration variables such as API keys, chunk size, and model settings.
    -   `data/` : contain the data.
        -   `publication.pdf`: The source document used for the RAG system.
-   `PART2_EVALUATION_METHODOLOGY/`: contain a document outlining the proposed system for evaluating RAG response quality.
    -   `Evaluation_methodology.pdf`
-   `exploration/` : contain the jupyter notebook file.
    - `rag_explore.ipynb` : learn and explore how to build RAG.
-   `README.md`: This file.
-   `requirements.txt`: Python dependencies.

## Prerequisites

-   Python 3.5
-   `pip` for package installation
-   An OpenAI API Key (for embeddings and LLM generation)

## Setup

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd <your-repo-name>
    ```


2.  **Install dependencies:**
    Navigate to the `PART1_RAG_IMPLEMENTATION` directory:
    ```bash
    cd PART1_RAG_IMPLEMENTATION
    pip install -r requirements.txt
    ```

3.  **Set up OpenAI API Key:**
    -   Rename `.env.example` to `.env` within the `PART1_RAG_IMPLEMENTATION` directory.
    -   Open the `.env` file and replace `"your_openai_api_key_here"` with your actual OpenAI API key:
        ```
        OpenAI_API_key="xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
        ```
    Alternatively, you can set the `OpenAI_API_key` as an environment variable in your system.

## Running Part 1: RAG Pipeline

1.  Ensure you are in the `PART1_RAG_IMPLEMENTATION` directory.
2.  Ensure `publication.pdf` is present in this directory.
3.  Execute the script:
    ```bash
    python pipeline.py
    ```

### Expected Output (Part 1)

The script will print the question posed to the RAG system and the answer generated by it. For example:


## Part 2: Evaluation Methodology

The written component for Part 2, explaining the design and implementation of a RAG response evaluation system, can be found in the file:

